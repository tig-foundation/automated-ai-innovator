@book{Silverman1986,
  author = {Silverman, B.W.},
  title = {Density Estimation for Statistics and Data Analysis},
  year = {1986},
  publisher = {Chapman \& Hall/CRC},
  address = {London},
  pages = {45},
  isbn = {978-0-412-24620-3}
}

@article{sitzmann2020implicit,
  title={Implicit neural representations with periodic activation functions},
  author={Sitzmann, Vincent and Martel, Julien and Bergman, Alexander and Lindell, David and Wetzstein, Gordon},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7462--7473},
  year={2020}
}

@misc{shumailov2023curse,
  title = {THE CURSE OF RECURSION: TRAINING ON GENERATED DATA MAKES MODELS FORGET},
  author = {Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Gal, Yarin and Papernot, Nicolas and Anderson, Ross},
  howpublished = {arXiv preprint arXiv:2307.15925},
  note = {University of Oxford, University of Cambridge, Imperial College London, University of Toronto \& Vector Institute, University of Edinburgh},
  year = {2023},
  url = {https://arxiv.org/abs/2307.15925}
}

@inproceedings{holt2024data,
  title={Data-driven discovery of dynamical systems in pharmacology using large language models},
  author={Holt, Samuel and Qian, Zhaozhi and Liu, Tennison and Weatherall, Jim and van der Schaar, Mihaela},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@inproceedings{merler2024context,
  title={In-context symbolic regression: Leveraging large language models for function discovery},
  author={Merler, Matteo and Haitsiukevich, Katsiaryna and Dainese, Nicola and Marttinen, Pekka},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)},
  pages={589--606},
  year={2024}
}

@inproceedings{lu2019nsga,
  title={Nsga-net: neural architecture search using multi-objective genetic algorithm},
  author={Lu, Zhichao and Whalen, Ian and Boddeti, Vishnu and Dhebar, Yashesh and Deb, Kalyanmoy and Goodman, Erik and Banzhaf, Wolfgang},
  booktitle={Proceedings of the genetic and evolutionary computation conference},
  pages={419--427},
  year={2019}
}


@book{banzhaf1998genetic,
  title={Genetic programming: an introduction: on the automatic evolution of computer programs and its applications},
  author={Banzhaf, Wolfgang and Nordin, Peter and Keller, Robert E and Francone, Frank D},
  year={1998},
  publisher={Morgan Kaufmann Publishers Inc.}
}


@inproceedings{wang2023review,
  title={A review on code generation with llms: Application and evaluation},
  author={Wang, Jianxun and Chen, Yixiang},
  booktitle={2023 IEEE International Conference on Medical Artificial Intelligence (MedAI)},
  pages={284--289},
  year={2023},
  organization={IEEE}
}


@article{liu2023your,
  title={Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation},
  author={Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and Zhang, Lingming},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={21558--21572},
  year={2023}
}


@article{koza1994genetic,
  title={Genetic programming as a means for programming computers by natural selection},
  author={Koza, John R},
  journal={Statistics and computing},
  volume={4},
  pages={87--112},
  year={1994},
  publisher={Springer}
}


@inproceedings{morris2024llm,
  title={Llm guided evolution-the automation of models advancing models},
  author={Morris, Clint and Jurado, Michael and Zutty, Jason},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={377--384},
  year={2024}
}


@article{lu2024ai,
  title={The ai scientist: Towards fully automated open-ended scientific discovery},
  author={Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David},
  journal={arXiv preprint arXiv:2408.06292},
  year={2024}
}


@article{aryal2024leveraging,
  title={Leveraging multi-AI agents for cross-domain knowledge discovery},
  author={Aryal, Shiva and Do, Tuyen and Heyojoo, Bisesh and Chataut, Sandeep and Gurung, Bichar Dip Shrestha and Gadhamshetty, Venkataramana and Gnimpieba, Etienne},
  journal={arXiv preprint arXiv:2404.08511},
  year={2024}
}


@article{li2024chain,
  title={Chain of ideas: Revolutionizing research via novel idea development with llm agents},
  author={Li, Long and Xu, Weiwen and Guo, Jiayan and Zhao, Ruochen and Li, Xingxuan and Yuan, Yuqian and Zhang, Boqiang and Jiang, Yuming and Xin, Yifei and Dang, Ronghao and others},
  journal={arXiv preprint arXiv:2410.13185},
  year={2024}
}


@article{romera2024mathematical,
  title={Mathematical discoveries from program search with large language models},
  author={Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and Balog, Matej and Kumar, M Pawan and Dupont, Emilien and Ruiz, Francisco JR and Ellenberg, Jordan S and Wang, Pengming and Fawzi, Omar and others},
  journal={Nature},
  volume={625},
  number={7995},
  pages={468--475},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{aglietti2024funbo,
  title={FunBO: Discovering Acquisition Functions for Bayesian Optimization with FunSearch},
  author={Aglietti, Virginia and Ktena, Ira and Schrouff, Jessica and Sgouritsa, Eleni and Ruiz, Francisco JR and Malek, Alan and Bellot, Alexis and Chiappa, Silvia},
  journal={arXiv preprint arXiv:2406.04824},
  year={2024}
}

@article{ellenberg2025generative,
  title={Generative modeling for mathematical discovery},
  author={Ellenberg, Jordan S and Fraser-Taliente, Cristofero S and Harvey, Thomas R and Srivastava, Karan and Sutherland, Andrew V},
  journal={arXiv preprint arXiv:2503.11061},
  year={2025}
}

@techreport{novikov2025alphaevolve,
  title={AlphaEvolve: A coding agent for scientific and algorithmic discovery},
  author={Novikov, Alexander and Vu, Ng{\^a}n and Eisenberger, Marvin and Dupont, Emilien and Huang, Po-Sen and Wagner, Adam Zsolt and Shirobokov, Sergey and Kozlovskii, Borislav and Ruiz, Francisco JR and Mehrabian, Abbas and others},
  year={2025},
  institution={Technical report, Google DeepMind, 05 2025. URL https://storage. googleapis~…}
}



@article{rosenblatt_perceptron_1958,
	title = {The perceptron: {A} probabilistic model for information storage and organization in the brain},
	volume = {65},
	issn = {1939-1471},
	shorttitle = {The perceptron},
	doi = {10.1037/h0042519},
	abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6},
	journal = {Psychological Review},
	author = {Rosenblatt, F.},
	year = {1958},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Brain, Cognition, Memory, Nervous System},
	pages = {386--408},
	file = {Rosenblatt - 1958 - The perceptron A probabilistic model for information storage and organization in the brain.pdf:/Users/hikarukilian/Zotero/storage/WLTU4U5G/Rosenblatt - 1958 - The perceptron A probabilistic model for information storage and organization in the brain.pdf:application/pdf;Snapshot:/Users/hikarukilian/Zotero/storage/N68EBN6X/doiLanding.html:text/html},
}


@inproceedings{nikolic_survey_2022,
	title = {A {Survey} of {Three} {Types} of {Processing} {Units}: {CPU}, {GPU} and {TPU}},
	shorttitle = {A {Survey} of {Three} {Types} of {Processing} {Units}},
	url = {https://ieeexplore.ieee.org/document/9828625},
	doi = {10.1109/ICEST55168.2022.9828625},
	abstract = {The CPU, GPU, and TPU are three different types of processing units. For the overall performance of the computer, the CPU is responsible. For delivering high-end graphics and video quality, the GPU is responsible. Along with the CPU, the GPU is a piece of additional hardware. TPU is used in the field of Artificial Intelligence, Machine Learning, and Deep Learning. Each of the three processing units has its own set of functions. This article may be of help to a reader with aim to understand the distinctions between the CPU, GPU, and TPU processing units.},
	urldate = {2024-11-29},
	booktitle = {2022 57th {International} {Scientific} {Conference} on {Information}, {Communication} and {Energy} {Systems} and {Technologies} ({ICEST})},
	author = {Nikolić, Goran S. and Dimitrijević, Bojan R. and Nikolić, Tatjana R. and Stojcev, Mile K.},
	month = jun,
	year = {2022},
	keywords = {Central Processing Unit, Computer performance, CPU, Deep learning, GPU, Graphics processing units, Hardware, hardware accelerator, Quality assessment, TPU, Video recording},
	pages = {1--6},
}


@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}


@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}


@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}


@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}


@article{wen2025unsupervised,
  title={Unsupervised Elicitation of Language Models},
  author={Wen, Jiaxin and Ankner, Zachary and Somani, Arushi and Hase, Peter and Marks, Samuel and Goldman-Wetzler, Jacob and Petrini, Linda and Sleight, Henry and Burns, Collin and He, He and others},
  journal={arXiv preprint arXiv:2506.10139},
  year={2025}
}


@article{ye2025robust,
  title={Robust reinforcement learning from human feedback for large language models fine-tuning},
  author={Ye, Kai and Zhou, Hongyi and Zhu, Jin and Quinzan, Francesco and Shi, Chengchung},
  journal={arXiv preprint arXiv:2504.03784},
  year={2025}
}