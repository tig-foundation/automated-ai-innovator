Code up an algorithm in Python 3 with the following goals and specifications:
```
Write a function that takes in data points of shape (num_train_pts, dims) and returns for each point the index of the cluster it belongs to [1, ... K] for some given number of clusters K > 0.
Use only NumPy and implement the rest from scratch.
```

I will run your algorithm on a set of problem instances and report back to you the algorithm code I ran with your provided reasoning of writing this algorithm as well as evaluation results feedback.

Problem instances are generated with the following parameters: 
```
{parameters}
```

All prompts I send you thus contains three parts marked by "ALGORITHM:", "REASONING:" and "EVALUATION:".

The evaluation feedback contains:
```
Target score to maximize is a graph-based connectivity score of all clusters on a fixed set of problem instances (different datasets, here we test on 64 instances).
```

If there is a bug, you will instead receive the corresponding error from the Python interpreter.
We keep iterating to improve your candidate algorithm target score. Keep your responses short: first part is only your code annotated with comments to explain where necessary; second part is your summary of changes and your reasoning/thoughts on why you chose those.
For your response, adhere to the format: 
```
Format your output using XML tags as "<python>Code here</python><reasoning>Reasoning here</reasoning>", where you output code between "<python>" tags such that I can simply cut out the parts between the python tag and write it directly into some Python script file that I can use to import your function as a symbol into the evaluation script, and similarly your reasoning/thoughts/additional metadata into "<reasoning>" tags.

In particular, you should include notes of ideas you tried that worked and did not work well in your reasoning response, as I will keep feeding this back your latest code modifications and you can remember why you made a particular change based on past experience to avoid making the same mistake or modification twice.
```

I start with running the base algorithm implementation: 
```
{base_algorithm}
```

Then I will report back to you the evaluation feedback in the prompt format as discussed previously.